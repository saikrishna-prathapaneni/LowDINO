{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install timm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e90CuYv_9mXW",
        "outputId": "0eae0401-29b4-4eb4-95bf-55bc997396ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting timm\n",
            "  Downloading timm-0.9.2-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.7 in /usr/local/lib/python3.10/dist-packages (from timm) (2.0.0+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm) (0.15.1+cu118)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm) (6.0)\n",
            "Collecting huggingface-hub (from timm)\n",
            "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors (from timm)\n",
            "  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7->timm) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7->timm) (16.0.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (2023.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (2.27.1)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (4.65.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (23.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (1.22.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (8.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.7->timm) (2.1.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (3.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7->timm) (1.3.0)\n",
            "Installing collected packages: safetensors, huggingface-hub, timm\n",
            "Successfully installed huggingface-hub-0.14.1 safetensors-0.3.1 timm-0.9.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import timm\n",
        "from torch.nn import functional as F\n",
        "from torchsummary import summary\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "aM-1cnTS9hCF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import timm\n",
        "from torch.nn import functional as F\n",
        "from torchsummary import summary\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "import numpy as np\n",
        "# from model import Head, MultiCrop,DinoLoss\n",
        "# from Augmentation import DataAugmentation\n",
        "# from PIL import ImagePath\n",
        "# from torchvision.datasets import ImageFolder\n",
        "# import pathlib\n",
        "# from torch.utils.data import DataLoader, SubsetRandomSampler\n",
        "# model and dim values\n",
        "\n",
        "\n",
        "mobile_models = {\n",
        "    'mobilevit_s':640,\n",
        "    'mobilevit_xs':640,\n",
        "    'mobilevit_xxs':640,\n",
        "    'mobilenetv2_035':640,\n",
        "    'mobilenetv2_075':640,\n",
        "    'mobilenetv2_100':640,\n",
        "    'resnet5m':512,   \n",
        "}\n",
        "\n",
        "class mobilenet(nn.Module):\n",
        "    def __init__(self,\n",
        "                 model:str = 'mobilevit_s',\n",
        "                 pretrained=False):\n",
        "        super(mobilenet,self).__init__()\n",
        "        self.backbone = timm.create_model(model,pretrained=pretrained)\n",
        "        self.backbone.reset_classifier(0)\n",
        "        self.num_features = self.backbone.num_features\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = self.backbone(x)\n",
        "        return x\n",
        "\n",
        "class MultiCrop(nn.Module):\n",
        "    \"\"\"\n",
        "    backbone: timm.models.vision_transformer.VisionTransformer\n",
        "    new_head: head\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 backbone,\n",
        "                 new_head,\n",
        "                 mobile_head=False\n",
        "                 ) -> None:\n",
        "        super().__init__()\n",
        "        self.mobile_head =mobile_head \n",
        "\n",
        "        #setting up the model\n",
        "        self.backbone = backbone\n",
        "        backbone.head= nn.Identity()\n",
        "        self.new_head = new_head\n",
        "\n",
        "\n",
        "    def forward(self,x):\n",
        "        \"\"\"\n",
        "        x is List of torch.Tensor of shape (n_samples, 3,size,size)\n",
        "        \n",
        "        \"\"\"\n",
        "        n_crops = len(x)\n",
        "        #print(\"len of batch \",len(x))\n",
        "        concatenated_tensor = torch.cat(x,dim=0) \n",
        "        # (n_samples*n_crops, 3, size, size)\n",
        "        # example batch size of 64 we have [640,3, 224,224] for size crops of 10: 2G,8L\n",
        "        \n",
        "        #print(\"shape of concat tensor\",concatenated_tensor.shape)\n",
        "        cls_embedding = self.backbone(concatenated_tensor) # (n_samples * n_crops, in_dim)\n",
        "        #print(cls_embedding.shape, \"cls embedding\")\n",
        "        logits =self.new_head(cls_embedding) # n_samples * n_crops, out_dim\n",
        "\n",
        "        chunks = logits.chunk(n_crops) # n_crops * (n_samples,outdim)\n",
        "        \n",
        "        return chunks\n",
        "\n",
        "\n",
        "class Head(nn.Module):\n",
        "    def __init__(self,\n",
        "                 in_dim,\n",
        "                 out_dim,\n",
        "                 hidden_dim = 512,\n",
        "                 bottleneck_dim = 256,\n",
        "                 n_layers =3,\n",
        "                 norm_last_layer=False,\n",
        "                 init_weights=[\"normal\",\"\"] # yet to define\n",
        "                 ) -> None:\n",
        "        super().__init__()\n",
        "        \n",
        "        # create a Multilayer perceptron based on the layer number from in dim to out dim\n",
        "       \n",
        "        if n_layers ==1:\n",
        "            self.mlp =nn.Linear(in_dim, bottleneck_dim)\n",
        "        else:\n",
        "            layers = [nn.Linear(in_dim, hidden_dim)]\n",
        "            layers.append(nn.SELU())\n",
        "            for _ in range(n_layers-2):\n",
        "                layers.append(nn.Linear(hidden_dim,hidden_dim))\n",
        "                layers.append(nn.SELU())\n",
        "            layers.append(nn.Linear(hidden_dim,bottleneck_dim))\n",
        "            self.mlp = nn.Sequential(*layers)\n",
        "        \n",
        "        \n",
        "        self.apply(self._init_weights)\n",
        "        self.last_layer = nn.utils.weight_norm(\n",
        "            nn.Linear(bottleneck_dim,out_dim,bias=False)\n",
        "        )\n",
        "        self.last_layer.weight_g.data.fill_(1)\n",
        "        if norm_last_layer:\n",
        "            self.last_layer.weight_g.requires_grad=False\n",
        "        \n",
        "    def _init_weights(self,m):\n",
        "        if isinstance(m,nn.Linear):\n",
        "            nn.init.normal_(m.weight,std=0.02)\n",
        "            if m.bias is not None:\n",
        "                nn.init.constant_(m.bias,0)\n",
        "\n",
        "    def forward(self,x):\n",
        "        x= self.mlp(x)\n",
        "        x= F.normalize(x,dim=-1,p=2)\n",
        "        x=self.last_layer(x)\n",
        "        return x\n",
        "    \n",
        "\n",
        "\n",
        "import torch.nn as nn\n",
        "import timm\n",
        "from torch.nn import functional as F\n",
        "\n",
        "\n",
        "\n",
        "class ResBlock(nn.Module):\n",
        "    def __init__(self,\n",
        "                inchannels,\n",
        "                outchannels,\n",
        "                kernel_size=3,\n",
        "                stride=1,\n",
        "                skip=True):\n",
        "        super().__init__()\n",
        "        # Determines whether to add the identity mapping skip connection\n",
        "        self.skip = skip\n",
        "        \n",
        "        # First block of the residual connection\n",
        "        self.block = nn.Sequential(\n",
        "            nn.Conv2d(inchannels,\n",
        "                    outchannels,\n",
        "                    kernel_size=kernel_size,\n",
        "                    stride=stride,\n",
        "                    padding=1,\n",
        "                    bias=False),\n",
        "            nn.BatchNorm2d(outchannels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(outchannels,\n",
        "                    outchannels,\n",
        "                    kernel_size=kernel_size,\n",
        "                    padding=1,\n",
        "                    bias=False),\n",
        "            nn.BatchNorm2d(outchannels),\n",
        "        )\n",
        "        \n",
        "        # If the stride is 2 or input channels and output channels do not match,\n",
        "        # then add a convolutional layer and a batch normalization layer to the identity mapping\n",
        "        if stride == 2 or inchannels != outchannels:\n",
        "            self.skip = False\n",
        "            self.skip_conv = nn.Conv2d(inchannels, outchannels, kernel_size=1, stride=stride, bias=False)\n",
        "            self.skip_bn = nn.BatchNorm2d(outchannels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.block(x)\n",
        "        \n",
        "        # If the skip connection is active, add the input to the output\n",
        "        # If the skip connection is not active, add the skip connection to the output\n",
        "        if not self.skip:\n",
        "            out += self.skip_bn(self.skip_conv(x))\n",
        "        else:\n",
        "            out += x\n",
        "        \n",
        "        out = F.relu(out.clone())\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet5M(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        \n",
        "        # Initial convolutional layer and batch normalization\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
        "        \n",
        "        # Residual blocks\n",
        "        self.resblock3 = ResBlock(64, 64, stride=1)\n",
        "        self.resblock6 = ResBlock(64, 64, stride=1)\n",
        "        self.resblock7 = ResBlock(64, 64, stride=1)\n",
        "        self.resblock8 = ResBlock(64, 128, stride=2)\n",
        "        self.resblock9 = ResBlock(128, 128, stride=1)\n",
        "        self.resblock10 = ResBlock(128, 128, stride=1)\n",
        "        self.resblock11 = ResBlock(128, 128, stride=1)\n",
        "        self.resblock12 = ResBlock(128, 128, stride=1)\n",
        "        self.resblock13 = ResBlock(128, 128, stride=1)\n",
        "        self.resblock14 = ResBlock(128, 512, stride=2)\n",
        "        \n",
        "        # Global average pooling and fully-connected layer\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d(output_size=(1, 1))\n",
        "        self.flat = nn.Flatten()\n",
        "        # self.fc = nn.Linear(in_features=512, out_features=2048, bias=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x.clone())\n",
        "        x = self.maxpool(x)\n",
        "        x = self.resblock3(x)\n",
        "        x = self.resblock6(x)\n",
        "        x = self.resblock7(x)\n",
        "        x = self.resblock8(x)\n",
        "        x = self.resblock9(x)\n",
        "        x = self.resblock10(x)\n",
        "        x = self.resblock11(x)\n",
        "        x = self.resblock12(x)\n",
        "        x = self.resblock13(x)\n",
        "        x = self.resblock14(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = self.flat(x)\n",
        "        # x = self.fc(x) \n",
        "        return x\n",
        "\n"
      ],
      "metadata": {
        "id": "Xs8iKEgvWWYR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "import torch.utils.data as data\n",
        "import torch.optim as optim\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    \n",
        "    transforms.ToTensor(),\n",
        "    # transforms.Resize((56,56)),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) \n",
        "])\n",
        "\n",
        "cifar_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "\n",
        "\n",
        "batch_size = 32\n",
        "dataloader = data.DataLoader(cifar_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "dino_model=torch.hub.load('facebookresearch/dino:main', 'dino_resnet50').to('cuda')\n",
        "\n",
        "resnet_model=ResNet5M().to('cuda')\n",
        "num_classes = 10 \n",
        "\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(resnet_model.parameters(), lr=0.001, momentum=0.9)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X8lTLac1ZHKX",
        "outputId": "76357558-da75-4742-fecb-eabc5f48a8a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:13<00:00, 12869839.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://github.com/facebookresearch/dino/zipball/main\" to /root/.cache/torch/hub/main.zip\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://dl.fbaipublicfiles.com/dino/dino_resnet50_pretrain/dino_resnet50_pretrain.pth\" to /root/.cache/torch/hub/checkpoints/dino_resnet50_pretrain.pth\n",
            "100%|██████████| 90.0M/90.0M [00:06<00:00, 15.1MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dino_model.eval()"
      ],
      "metadata": {
        "id": "-2mff3XStJAB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m = torch.randn(1, 3, 32, 32).to('cuda')\n",
        "reduction_factor = 4\n",
        "\n",
        "reduced_dino_model = nn.Sequential(\n",
        "    nn.AdaptiveAvgPool1d(2048),\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(2048, 2048 // reduction_factor),\n",
        ").to('cuda')\n",
        "\n",
        "# reduced_dino_model.eval()\n",
        "\n",
        "# Perform forward pass on the reduced DINO model\n",
        "with torch.no_grad():\n",
        "    # dino_features = reduced_dino_model(dino_model(m))\n",
        "    print(reduced_dino_model(dino_model(m)).shape)\n",
        "    # print(dino_model(m)[0].shape)\n",
        "\n",
        "\n",
        "# for p in dino_model.parameters():\n",
        "#   p.requires_grad=False\n",
        "\n",
        "# resnet_model(m).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJXnKjVtZwlc",
        "outputId": "42205fbf-2a44-4070-de0a-7fb6539245fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 512])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "noEK2RPg8yIQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5195f24f-70eb-4de9-fc77-7f1102624ea6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 512])\n",
            "tensor(6, device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "temperature = 3.0  # Temperature value for distillation\n",
        "\n",
        "# Assuming you have a dataloader for your dataset\n",
        "for images, labels in dataloader:\n",
        "    images = images.to('cuda')\n",
        "    labels = labels.to('cuda')\n",
        "\n",
        "    # Forward pass on DINO v1 ResNet50 backbone\n",
        "    with torch.no_grad():\n",
        "        dino_features = reduced_dino_model(dino_model(images))/ temperature\n",
        "    # Forward pass on ResNet model\n",
        "    resnet_outputs = resnet_model(images) / temperature\n",
        "    # print(dino_features.shape)\n",
        "    # print(resnet_outputs.shape)\n",
        "    # break\n",
        "\n",
        "    # Calculate the loss with distillation\n",
        "    distillation_loss = torch.nn.functional.kl_div(\n",
        "        torch.nn.functional.log_softmax(resnet_outputs, dim=1),\n",
        "        torch.nn.functional.softmax(dino_features, dim=1),\n",
        "        reduction='batchmean'\n",
        "    )\n",
        "\n",
        "    # Calculate the classification loss\n",
        "    classification_loss = criterion(resnet_outputs, labels)\n",
        "\n",
        "    # Calculate the total loss\n",
        "    total_loss = distillation_loss + classification_loss\n",
        "\n",
        "    # Backward and optimize\n",
        "    optimizer.zero_grad()\n",
        "    total_loss.backward()\n",
        "    optimizer.step()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "import torch.utils.data as data\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    \n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) \n",
        "])\n",
        "\n",
        "cifar_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "\n",
        "batch_size = 32\n",
        "dataloader = data.DataLoader(cifar_dataset, batch_size=batch_size, shuffle=False)\n",
        "num_samples = len(cifar_dataset)\n",
        "embedding_size = 512\n",
        "embeddings = np.zeros((num_samples, embedding_size))\n",
        "\n",
        "\n",
        "resnet_model.eval()\n",
        "resnet_model=resnet_model.to('cuda')\n",
        "with torch.no_grad():\n",
        "    image_idx = 0\n",
        "    for images, _ in dataloader:\n",
        "        batch_size = images.size(0)\n",
        "        images = images.to('cuda')  \n",
        "        \n",
        "        outputs = resnet_model(images)\n",
        "        # outputs = model(images)\n",
        "        \n",
        "        embeddings[image_idx:image_idx+batch_size] = outputs.squeeze().cpu().numpy()\n",
        "        \n",
        "        image_idx += batch_size\n",
        "\n"
      ],
      "metadata": {
        "id": "mUoRCjAvXugX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec01c67c-04a8-4af9-dcb5-2956edefeeb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "k = 5\n",
        "knn = NearestNeighbors(n_neighbors=k)\n",
        "knn.fit(embeddings)\n",
        "\n",
        "test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
        "\n",
        "\n",
        "output_tensor = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, _ in test_loader:\n",
        "        images = images.to('cuda') \n",
        "        output = resnet_model(images)\n",
        "        # output = model(images)\n",
        "        output_tensor.append(output.squeeze().cpu().numpy())\n",
        "\n",
        "output_tensor = np.stack(output_tensor)\n",
        "_, indices = knn.kneighbors(output_tensor)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0wsTWdTIVod3",
        "outputId": "f6ac22f8-d721-4628-8102-db574d9499cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_array = cifar_dataset.targets\n",
        "true_test_labels=test_dataset.targets\n",
        "test_labels = []\n",
        "for i in range(len(indices)):\n",
        "    train_indices = indices[i]\n",
        "    first_train_label = label_array[train_indices[0]]\n",
        "    test_labels.append(first_train_label)\n",
        "\n",
        "\n",
        "accuracy_score(true_test_labels,test_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SIog0G7hVqp_",
        "outputId": "b05678df-e866-4ab5-e8bf-8dd21b6a7e6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5196"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "I0gMZDxni-_F"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}